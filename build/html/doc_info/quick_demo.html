

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Knight demo介绍 &mdash; Knight_doc V3.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=eb26d1a0"></script>
      <script src="../_static/doctools.js?v=888ff710"></script>
      <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Knight_doc
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Knight 工具链</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="doc_info.html">1. 修改记录</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/overview.html">2. 使用指南综述</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_demo/quick_demo.html">3. 简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_demo/quick_demo.html#id2">4. 开发环境准备</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_demo/quick_demo.html#knight">5. Knight命令说明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_demo/quick_demo.html#id6">6. 模型转换配置文件示例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_demo/quick_demo.html#id7">7. 模型转换命令执行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_demo/quick_demo.html#id8">8. 仿真命令执行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_demo/quick_demo.html#id13">9. 板端运行</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_demo/quick_demo.html#id22">10. 功能特性说明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user_guides_base/quant.html">11. 量化使用指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user_guides_base/compile.html">12. 编译仿真性能分析使用指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user_guides_base/sdk.html">13. SDK使用指南</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">附录</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/quant_faq.html">1. 量化工具FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../op/op.html">2. 算子支持列表</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Knight_doc</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Knight demo介绍</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/doc_info/quick_demo.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p>TS.Knight-快速上手指南</p>
<p>|image1|</p>
<p><strong>COPYRIGHT© 2024北京清微智能科技有限公司，保留所有权利。</strong></p>
<p>本文档的产权属于北京清微智能科技有限公司(下称清微智能)。本文档仅能分布给:(i)拥有合法雇佣关系，并需要本文档的信息的北京清微系统员工，或(ii)非北京清微组织但拥有合法合作关系，并且其需要本文档的信息的合作方。对于本文档，禁止任何在专利、版权或商业秘密过程中，授予或暗示的可以使用该文档。在没有得到北京清微智能科技有限公司的书面许可前，不得复制本文档的任何部分，传播、转录、储存在检索系统中或翻译成任何语言或计算机语言。</p>
<p><strong>商标申明</strong></p>
<p>北京清微系统的LOGO和其它所有商标归北京清微智能科技有限公司所有，所有其它产品或服务名称归其所有者拥有。</p>
<p><strong>注意</strong></p>
<p>您购买的产品、服务或特性等应受清微智能商业合同和条款的约束，本文档中描述的全部或部分产品、服务或特性可能不在您的购买或使用范围之内。除非合同另有约定，清微智能对本文档内容不做任何明示或默示的声明或保证。</p>
<p>由于产品版本升级或其他原因，本文档内容会不定期进行更新。除非另有约定，本文档仅作为使用指导，本文档中的所有陈述、信息和建议不构成任何明示或暗示的担保。</p>
<p><strong>北京清微智能科技有限公司</strong></p>
<p><strong>地址：</strong>\ 北京市海淀区西三旗金隅科技园一期1号楼8层</p>
<p><strong>网址：</strong>\ <code class="docutils literal notranslate"><span class="pre">www.tsingmicro.com</span> <span class="pre">&lt;http://www.tsingmicro.com&gt;</span></code>__</p>
<p><strong>客户服务邮箱：</strong>\ tm&#64;tsingmicro.com</p>
<p>前言</p>
<p>概述</p>
<p>为便于客户更直观、更快速的了解清微智能骑士工具链TS.Knight的用法，将自己的业务神经网络模型快速的在清微智能芯片产品上部署，特针对工具链各模块（Knight量化工具、Knight
RNE编译器、Knigh RNE模拟器、Knight RNE
性能分析器）提供结合语音、图像业务的快速上手用例。同时对这些用例进行讲解，以期帮助用户达到快速上手的目的。</p>
<p>这些用例结合具体业务只用于演示工具链的典型使用流程，使用的数据量较少，所以精度不具有参考价值，不代表工具链的实际精度效果。用例中的一些脚本，比如语音、图像数据的预处理，客户可借鉴，如果有类似业务场景可在其基础上进行修改。客户如果想发挥出工具链的最大能力、更灵活的使用、应用到更复杂的场景，还需仔细阅读TS.Knight工具链各模块相应的使用指南文档。</p>
<p>产品版本</p>
<p>与本文档相对应的产品版本如下。</p>
<p>+————–+——————–+———————————-+
| <strong>文档版本</strong> | <strong>软件版本</strong>       | <strong>芯片版本</strong>                     |
+==============+====================+==================================+
| V3.1         | TS.Knight_3.0.0    | TX5105C                          |
+————–+——————–+———————————-+
|              |                    | TX5103C                          |
+————–+——————–+———————————-+
|              |                    | TX5105CV100                      |
+————–+——————–+———————————-+
|              |                    | TX5103CV100                      |
+————–+——————–+———————————-+
|              |                    | TX5101C                          |
+————–+——————–+———————————-+
|              |                    | TX5101D                          |
+————–+——————–+———————————-+
|              |                    | TX5101E                          |
+————–+——————–+———————————-+
|              |                    | TX5368AV200                      |
+————–+——————–+———————————-+
|              |                    | TX5339AV200                      |
+————–+——————–+———————————-+
|              |                    | TX5335AV200                      |
+————–+——————–+———————————-+
|              |                    | TX5215CV200                      |
+————–+——————–+———————————-+
|              |                    | TX5215DV200                      |
+————–+——————–+———————————-+
|              |                    | TX5215DV300                      |
+————–+——————–+———————————-+
|              |                    | TX5215EV300                      |
+————–+——————–+———————————-+
|              |                    | TX5239DV200                      |
+————–+——————–+———————————-+
|              |                    | TX5239DV220                      |
+————–+——————–+———————————-+
|              |                    | TX5239DV300                      |
+————–+——————–+———————————-+
|              |                    | TX5112CV201                      |
+————–+——————–+———————————-+
|              |                    | TX5112DV201                      |
+————–+——————–+———————————-+
|              |                    | TX5112CV300                      |
+————–+——————–+———————————-+
|              |                    | TX5112DV300                      |
+————–+——————–+———————————-+
|              |                    | TX5239CV201                      |
+————–+——————–+———————————-+
|              |                    | TX5239DV201                      |
+————–+——————–+———————————-+
|              |                    | TX5336AV200                      |
+————–+——————–+———————————-+
|              |                    | TX5256AV200                      |
+————–+——————–+———————————-+</p>
<p>读者对象</p>
<p>本文档（本指南）主要适用于以下工程师：</p>
<ul class="simple">
<li><p>技术支持工程师</p></li>
<li><p>算法工程师</p></li>
<li><p>软件工程师</p></li>
</ul>
<p>阅读建议</p>
<p>建议按照如下顺序阅读TS.Knight相关文档。</p>
<p>|C:\Users\wangyanlong\AppData\Roaming\feiq\RichOle\3720703816.bmp|</p>
<p>修订记录</p>
<p>修订记录累积了每次文档更新的说明。最新版本的文档包含以前所有文档版本的更新内容。</p>
<p>+———-+—————————————+——————+
| <strong>文     | <strong>修订说明</strong>                          | <strong>修订日期</strong>     |
| 档版本</strong> |                                       |                  |
+==========+=======================================+==================+
| V1.0     | 首次发布                              | 2022年10月25日   |
+———-+—————————————+——————+
| V1.1     | 1. 第1.1章节                          | 2023年2月21日    |
|          |                                       |                  |
|          | 新增Knight example模型介绍            |                  |
|          |                                       |                  |
|          | 2. 第1.2章节                          |                  |
|          |                                       |                  |
|          | 新增目录介绍                          |                  |
|          |                                       |                  |
|          | 3. 第1.3章节                          |                  |
|          |                                       |                  |
|          | 新增Knight demo运行方式               |                  |
|          |                                       |                  |
|          | 4. 第1.3.1章节                        |                  |
|          |                                       |                  |
|          | 修改-f命令参数描述                    |                  |
|          |                                       |                  |
|          | 5. 第2章                              |                  |
|          |                                       |                  |
|          | 修改部分内容说明                      |                  |
|          |                                       |                  |
|          | 6. 第3.1.5章节                        |                  |
|          |                                       |                  |
|          | 修改 Knight quant tf –h相关路径       |                  |
|          |                                       |                  |
|          | 7. 第3.3.3章节                        |                  |
|          |                                       |                  |
|          | 修改pytorch相关路径说明               |                  |
|          |                                       |                  |
|          | 8. 第3.3.3.1章                        |                  |
|          |                                       |                  |
|          | resnet和                              |                  |
|          | yolove5数据处理参考路径修改为绝对路径 |                  |
|          |                                       |                  |
|          | 9. 第3.3.4章节                        |                  |
|          |                                       |                  |
|          | 修改量化命令及量化步骤说明            |                  |
|          |                                       |                  |
|          | 10. 第3.4章节                         |                  |
|          |                                       |                  |
|          | 命令行添加paddle参数                  |                  |
|          |                                       |                  |
|          | 11. 第3.4.1章节                       |                  |
|          |                                       |                  |
|          | 修改文件目录说明                      |                  |
|          |                                       |                  |
|          | 12. 第3.4.4.2章节                     |                  |
|          |                                       |                  |
|          | 修改ONNX相关路径描述                  |                  |
|          |                                       |                  |
|          | 13. 第3.6章节                         |                  |
|          |                                       |                  |
|          | 修改RNE库相关描述                     |                  |
|          |                                       |                  |
|          | 14. 第3.6.3章节                       |                  |
|          |                                       |                  |
|          | 修改rne-comp                          |                  |
|          | ile/rne-sim/rne-profiling帮助信息截图 |                  |
|          |                                       |                  |
|          | 修改rne-profiling截图                 |                  |
+———-+—————————————+——————+
| V1.2     | 1.  新增2.2章节                       | 2023年5月17日    |
|          |                                       |                  |
|          | 2.                                    |                  |
|          |  修改1.2.1章节，新增Knight_MC_example |                  |
|          |                                       |                  |
|          | 3.  修改3.8 /3.9/4.2.6/5.2.2 章节     |                  |
|          |                                       |                  |
|          | 4.  将r                               |                  |
|          | eadygo_c 相关改成 simple_forward_demo |                  |
|          |                                       |                  |
|          | 5.  修改2.1章节，补充Knight-MC        |                  |
|          |     demo说明                          |                  |
|          |                                       |                  |
|          | 6.  新增章节3.5 ，增加Knight-MC demo  |                  |
|          |     说明                              |                  |
|          |                                       |                  |
|          | 7.  修改章节3.1/3.2/3.3               |                  |
|          | /3.4/3.7,修改输出目录相关的截图和内容 |                  |
|          |                                       |                  |
|          | 8.  修改章                            |                  |
|          | 节1.1，增加容器内外的example示例介绍  |                  |
|          |                                       |                  |
|          | 9.  修改章节2.2标题                   |                  |
|          |                                       |                  |
|          | 10. 修改章节3.3.                      |                  |
|          | 3.2，修改章节3.3.4.2，新增章节3.7.3.2 |                  |
|          |                                       |                  |
|          | 11. 修改章节1，增加示意图             |                  |
|          |                                       |                  |
|          | 12. 增加“阅读建议”章节                |                  |
|          |                                       |                  |
|          | 13. 修改章节1.3.1，padd               |                  |
|          | le模型，不指定—use-onnx时，命令不生效 |                  |
|          |                                       |                  |
|          | 14. 修改章节1.1 的yolov5              |                  |
|          |     demo的文                          |                  |
|          | 件结构的更新及demo场景新增onnx的部分  |                  |
|          |                                       |                  |
|          | 15. 修改章节3.3 ，3.4，yolov5         |                  |
|          |     pytorch模型use-onnx的demo介绍部分 |                  |
|          |                                       |                  |
|          | 16. 修改3.5.3章节，同步稀疏输出目录   |                  |
|          |                                       |                  |
|          | 17. 修改3.7.3及                       |                  |
|          | 3.3.3等章节，将部分有误的命令示例更正 |                  |
|          |                                       |                  |
|          | 18.                                   |                  |
|          | 修改9.9.3章节、4.2章节、5.2.2章节引用 |                  |
|          |                                       |                  |
|          | 19. 修                                |                  |
|          | 改3.4.4小节，将相对路径更新为绝对路径 |                  |
+———-+—————————————+——————+
| V1.3     | 1. 修改3.6.2，修改输出路径            | 2023年11月1日    |
|          |                                       |                  |
|          | 2. 修改3.4.1,                         |                  |
|          | 更新补充demo的onnx文件路径            |                  |
|          |                                       |                  |
|          | 3.                                    |                  |
|          | 修改芯片类型及各芯片发布lib名等信息   |                  |
|          |                                       |                  |
|          | 4. 修改yolov5的demo演示步骤           |                  |
|          |                                       |                  |
|          | 5.                                    |                  |
|          | 修改芯片类型及各芯片发布lib名等信息   |                  |
|          |                                       |                  |
|          | 6. 修改章节引用等信息，lib名信息      |                  |
|          |                                       |                  |
|          | 7. 删除TF量化平台相关内容             |                  |
|          |                                       |                  |
|          | 8. 新增第6章节                        |                  |
|          |                                       |                  |
|          | 9. 更新示例名及容器内目录名           |                  |
|          |                                       |                  |
|          | 10. 更新示例目录名称等                |                  |
|          |                                       |                  |
|          | 11. 更新demo资源结构图等              |                  |
|          |                                       |                  |
|          | 12. 更新3.4章节，更新目录和截图       |                  |
|          |                                       |                  |
|          | 13. 更新图表及个别文字                |                  |
|          |                                       |                  |
|          | 14. 文档目录进行大范围整改            |                  |
|          |                                       |                  |
|          | 15. 文档更新示例名，引用等信息        |                  |
|          |                                       |                  |
|          | 16. 修改板端部署相关示例              |                  |
+———-+—————————————+——————+
| V2.1     | 1. 删除caffe量化平台的相关内容        | 2024年3月4日     |
|          |                                       |                  |
|          | 2. 更新芯片列表                       |                  |
|          |                                       |                  |
|          | 3. 更新yolov5 demo说明                |                  |
|          |                                       |                  |
|          | 4.                                    |                  |
|          | 更新3.1.3节中yolov5模型切换使用的说明 |                  |
|          |                                       |                  |
|          | 5. 更新demo用途的介绍                 |                  |
|          |                                       |                  |
|          | 6. 删除不再支持的芯片组介绍           |                  |
|          |                                       |                  |
|          | 7. 删除不再支持的量化平台介绍         |                  |
+———-+—————————————+——————+
| V2.3     | 1. 更新demo脚本名称                   | 2024年7月24日    |
|          |                                       |                  |
|          | 2. 更新demo执行过程的路径名           |                  |
|          |                                       |                  |
|          | 3. 更新量化后的MAP参数示范章节        |                  |
+———-+—————————————+——————+
| V3.1     | 1.                                    | 2024年9页24日    |
|          | 更                                    |                  |
|          | 新编译器、模拟器、性能分析器使用名称  |                  |
|          |                                       |                  |
|          | 2. 更新demo图片及rc文件的使用         |                  |
+———-+—————————————+——————+</p>
<p>名词解释</p>
<p>+—————————+——————————————+
| <strong>名词</strong>                  | <strong>说明</strong>                                 |
+===========================+==========================================+
| Knight                    | 清微骑士工具链英文名称                   |
+—————————+——————————————+
| QAT                       | Quantization Aware                       |
|                           | Training，量化感知训练                   |
+—————————+——————————————+
| RNE                       | 可重构神经网络加速引擎                   |
+—————————+——————————————+
| Finetune                  | 微调                                     |
+—————————+——————————————+
| IR定点模型                | 中间表示模型，指                         |
|                           | Caffe定点模型或ONNX定点模型              |
+—————————+——————————————+</p>
<p>目录</p>
<p><code class="docutils literal notranslate"><span class="pre">1.</span> <span class="pre">Knight</span> <span class="pre">demo介绍</span> <span class="pre">&lt;#knight-demo介绍&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">11</span> <span class="pre">&lt;#knight-demo介绍&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">1.1.</span> <span class="pre">Knight</span> <span class="pre">demo整体介绍</span> <span class="pre">&lt;#knight-demo整体介绍&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">11</span> <span class="pre">&lt;#knight-demo整体介绍&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">1.2.</span> <span class="pre">Knight</span> <span class="pre">demo目录介绍</span> <span class="pre">&lt;#knight-demo目录介绍&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">12</span> <span class="pre">&lt;#knight-demo目录介绍&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">1.2.1.</span> <span class="pre">docker镜像内demo目录介绍</span> <span class="pre">&lt;#docker镜像内demo目录介绍&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">12</span> <span class="pre">&lt;#docker镜像内demo目录介绍&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">1.2.2.</span> <span class="pre">docker镜像外demo目录介绍</span> <span class="pre">&lt;#docker镜像外demo目录介绍&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">13</span> <span class="pre">&lt;#docker镜像外demo目录介绍&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">1.3.</span> <span class="pre">Knight</span> <span class="pre">demo运行方式</span> <span class="pre">&lt;#knight-demo运行方式&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">13</span> <span class="pre">&lt;#knight-demo运行方式&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">1.3.1.</span> <span class="pre">通过demo命令行运行</span> <span class="pre">&lt;#通过demo命令行运行&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">13</span> <span class="pre">&lt;#通过demo命令行运行&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">1.3.2.</span> <span class="pre">通过demo脚本运行</span> <span class="pre">&lt;#通过demo脚本运行&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">14</span> <span class="pre">&lt;#通过demo脚本运行&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">2.</span> <span class="pre">开发流程</span> <span class="pre">&lt;#开发流程&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">14</span> <span class="pre">&lt;#开发流程&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">2.1.</span> <span class="pre">AI全栈应用开发流程</span> <span class="pre">&lt;#ai全栈应用开发流程&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">14</span> <span class="pre">&lt;#ai全栈应用开发流程&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">2.2.</span> <span class="pre">模型部署资源生成开发流程</span> <span class="pre">&lt;#模型部署资源生成开发流程&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">16</span> <span class="pre">&lt;#模型部署资源生成开发流程&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">2.3.</span> <span class="pre">开发流程示例</span> <span class="pre">&lt;#开发流程示例&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">17</span> <span class="pre">&lt;#开发流程示例&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">2.3.1.</span> <span class="pre">目标检测场景</span> <span class="pre">&lt;#目标检测场景&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">17</span> <span class="pre">&lt;#目标检测场景&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">2.3.2.</span> <span class="pre">图像分类场景</span> <span class="pre">&lt;#图像分类场景&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">18</span> <span class="pre">&lt;#图像分类场景&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.</span> <span class="pre">模型部署资源生成快速指南</span> <span class="pre">&lt;#模型部署资源生成快速指南&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">19</span> <span class="pre">&lt;#模型部署资源生成快速指南&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.1.</span> <span class="pre">Quant</span> <span class="pre">&lt;#quant&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">20</span> <span class="pre">&lt;#quant&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.1.1.</span> <span class="pre">命令行运行方式</span> <span class="pre">&lt;#命令行运行方式&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">20</span> <span class="pre">&lt;#命令行运行方式&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.1.2.</span> <span class="pre">脚本运行方式</span> <span class="pre">&lt;#脚本运行方式&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">20</span> <span class="pre">&lt;#脚本运行方式&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.1.3.</span> <span class="pre">重要步骤</span> <span class="pre">&lt;#重要步骤&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">20</span> <span class="pre">&lt;#重要步骤&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.2.</span> <span class="pre">RNE</span> <span class="pre">&lt;#rne&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">24</span> <span class="pre">&lt;#rne&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.2.1.</span> <span class="pre">命令行运行方式</span> <span class="pre">&lt;#命令行运行方式-1&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">24</span> <span class="pre">&lt;#命令行运行方式-1&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.2.2.</span> <span class="pre">脚本运行方式</span> <span class="pre">&lt;#脚本运行方式-1&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">24</span> <span class="pre">&lt;#脚本运行方式-1&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.2.3.</span> <span class="pre">重要步骤</span> <span class="pre">&lt;#重要步骤-1&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">24</span> <span class="pre">&lt;#重要步骤-1&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.3.</span> <span class="pre">model_check</span> <span class="pre">&lt;#model_check&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">25</span> <span class="pre">&lt;#model_check&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.4.</span> <span class="pre">compare</span> <span class="pre">&lt;#compare&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">25</span> <span class="pre">&lt;#compare&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.5.</span> <span class="pre">Finetune库demo</span> <span class="pre">&lt;#finetune库demo&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">27</span> <span class="pre">&lt;#finetune库demo&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.5.1.</span> <span class="pre">demo文件夹说明</span> <span class="pre">&lt;#demo文件夹说明&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">27</span> <span class="pre">&lt;#demo文件夹说明&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.5.2.</span> <span class="pre">demo运行说明</span> <span class="pre">&lt;#demo运行说明&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">27</span> <span class="pre">&lt;#demo运行说明&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.5.3.</span> <span class="pre">重要步骤说明</span> <span class="pre">&lt;#重要步骤说明&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">28</span> <span class="pre">&lt;#重要步骤说明&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.6.</span> <span class="pre">Knight-MC库demo</span> <span class="pre">&lt;#knight-mc库demo&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">29</span> <span class="pre">&lt;#knight-mc库demo&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.6.1.</span> <span class="pre">demo文件夹说明</span> <span class="pre">&lt;#demo文件夹说明-1&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">29</span> <span class="pre">&lt;#demo文件夹说明-1&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.6.2.</span> <span class="pre">demo运行说明</span> <span class="pre">&lt;#demo运行说明-1&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">29</span> <span class="pre">&lt;#demo运行说明-1&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">3.6.3.</span> <span class="pre">重要步骤说明</span> <span class="pre">&lt;#重要步骤说明-1&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">29</span> <span class="pre">&lt;#重要步骤说明-1&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">4.</span> <span class="pre">应用开发快速指南</span> <span class="pre">&lt;#应用开发快速指南&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">31</span> <span class="pre">&lt;#应用开发快速指南&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">4.1.</span> <span class="pre">模拟库</span> <span class="pre">&lt;#模拟库&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">31</span> <span class="pre">&lt;#模拟库&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">4.1.1.</span> <span class="pre">命令行运行方式</span> <span class="pre">&lt;#命令行运行方式-2&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">31</span> <span class="pre">&lt;#命令行运行方式-2&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">4.1.2.</span> <span class="pre">脚本运行方式</span> <span class="pre">&lt;#脚本运行方式-2&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">31</span> <span class="pre">&lt;#脚本运行方式-2&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">4.1.3.</span> <span class="pre">重要步骤</span> <span class="pre">&lt;#重要步骤-2&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">31</span> <span class="pre">&lt;#重要步骤-2&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">4.2.</span> <span class="pre">运行时库</span> <span class="pre">&lt;#运行时库&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">32</span> <span class="pre">&lt;#运行时库&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">4.2.1.</span> <span class="pre">相关文件说明</span> <span class="pre">&lt;#相关文件说明&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">32</span> <span class="pre">&lt;#相关文件说明&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">4.2.2.</span> <span class="pre">demo运行说明</span> <span class="pre">&lt;#demo运行说明-2&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">33</span> <span class="pre">&lt;#demo运行说明-2&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">4.3.</span> <span class="pre">板端环境搭建及部署</span> <span class="pre">&lt;#板端环境搭建及部署&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">33</span> <span class="pre">&lt;#板端环境搭建及部署&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">4.3.1.</span> <span class="pre">环境准备</span> <span class="pre">&lt;#环境准备&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">33</span> <span class="pre">&lt;#环境准备&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">4.3.2.</span> <span class="pre">板端运行</span> <span class="pre">&lt;#板端运行&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">34</span> <span class="pre">&lt;#板端运行&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">5.</span> <span class="pre">自定义算子开发快速指南</span> <span class="pre">&lt;#自定义算子开发快速指南&gt;</span></code>__
<code class="docutils literal notranslate"><span class="pre">37</span> <span class="pre">&lt;#自定义算子开发快速指南&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">5.1.</span> <span class="pre">脚本运行方式</span> <span class="pre">&lt;#脚本运行方式-3&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">37</span> <span class="pre">&lt;#脚本运行方式-3&gt;</span></code>__</p>
<p><code class="docutils literal notranslate"><span class="pre">5.2.</span> <span class="pre">重要步骤</span> <span class="pre">&lt;#重要步骤-3&gt;</span></code>__ <code class="docutils literal notranslate"><span class="pre">37</span> <span class="pre">&lt;#重要步骤-3&gt;</span></code>__</p>
<section id="knight-demo">
<h1>Knight demo介绍<a class="headerlink" href="#knight-demo" title="Permalink to this heading"></a></h1>
<p>Knight
demo是一系列基于智能语音、计算机视觉等领域的典型端到端应用sample，用来端到端的演示Knight工具链的使用流程和具体用法，覆盖Knight工具链的全部功能模块。</p>
<p>说明：</p>
<p>Knight demo的定位是演示Knight工具链使用流程及用法，而非产品化的工程代码，不建议客户在产品中直接使用。</p>
<p>尤其是业务的前后处理代码，仅服务于demo演示，未经过大规模数据测试。</p>
<section id="id1">
<h2>Knight demo整体介绍<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h2>
<p>整体分布如下：</p>
<p>|\\192.168.60.89\home$\chenfan\Desktop\流程图 (13).jpg|</p>
<p>具体demo如下（每一行为一个demo）：</p>
<p>+—-+——-+—–+——+—–+——+—————————+
| ** | <strong>模  | *   | <strong>量 | *   | <strong>业 | <strong>Demo目的</strong>              |
| de | 型名  | <em>模 | 化平 | <em>中 | 务场 |                           |
| mo | 称</em></em>  | 型  | 台</strong> | 间I | 景</strong> |                           |
| 编 |       | **  |      | R</strong> |      |                           |
| 号 |       |     |      |     |      |                           |
| ** |       | *   |      |     |      |                           |
|    |       | *框 |      |     |      |                           |
|    |       | 架  |      |     |      |                           |
|    |       | **  |      |     |      |                           |
+====+=======+=====+======+=====+======+===========================+
| 1  | y     | P   | ONNX | O   | 目标 | 演示Py                    |
|    | olov5 | yto |      | NNX | 检测 | torch复杂业务模型量化功能 |
|    |       | rch |      |     |      |                           |
+—-+——-+—–+——+—–+——+—————————+
| 2  | y     | O   | ONNX | O   | 目标 | 演示                      |
|    | olov5 | NNX |      | NNX | 检测 | ONNX复杂业务模型量化功能  |
+—-+——-+—–+——+—–+——+—————————+
| 3  | res   | P   | ONNX | O   | 图像 | 演示Pytorc                |
|    | net18 | yto |      | NNX | 分类 | h模型使用ONNX量化工具功能 |
|    |       | rch |      |     |      |                           |
+—-+——-+—–+——+—–+——+—————————+
| 4  | res   | O   | ONNX | O   | 图像 | 演示ONNX模型基础量化功能  |
|    | net18 | NNX |      | NNX | 分类 |                           |
+—-+——-+—–+——+—–+——+—————————+
| 5  | res   | Ca  | ONNX | O   | 图像 | 演示Caff                  |
|    | net18 | ffe |      | NNX | 分类 | e模型使用ONNX量化工具功能 |
+—-+——-+—–+——+—–+——+—————————+
| 6  | res   | TF  | ONNX | O   | 图像 | 演示T                     |
|    | net18 |     |      | NNX | 分类 | F模型使用ONNX量化工具功能 |
+—-+——-+—–+——+—–+——+—————————+
| 7  | res   | Pad | ONNX | O   | 图像 | 演示Paddl                 |
|    | net18 | dle |      | NNX | 分类 | e模型使用ONNX量化工具功能 |
+—-+——-+—–+——+—–+——+—————————+
| 8  | gru   | TF  | ONNX | O   | 语音 | 演示T                     |
|    |       |     |      | NNX | 检测 | F的语音检测模型的量化功能 |
+—-+——-+—–+——+—–+——+—————————+
| 9  | re    | Ca  | C    | Ca  | 图像 | 演示Caffe                 |
|    | snet1 | ffe | affe | ffe | 分类 | IR自定义算子功能          |
|    | 8_ops |     |      |     |      |                           |
+—-+——-+—–+——+—–+——+—————————+</p>
<p>当前各系列芯片支持的demo如下：</p>
<p>+——————————————–+————————-+
| <strong>芯片型号</strong>                               | <strong>支持demo编号</strong>        |
+============================================+=========================+
| TX510x                                     | 1~8                     |
+——————————————–+————————-+
| TX5336x-TX5256x                            | 1~8                     |
+——————————————–+————————-+
| TX5368x_TX5339x_TX5335x                    | 1~9                     |
+——————————————–+————————-+
| TX5215x_TX5239x200_TX5239x220_TX5239x300   | 1~8                     |
+——————————————–+————————-+
| TX5112x_TX5239x201                         | 1~8                     |
+——————————————–+————————-+</p>
<p><strong>注意：本文档仅以TX5368AV200为例进行demo演示，如需演示其他芯片demo,
仅修改–chip参数即可。</strong></p>
</section>
<section id="id2">
<h2>Knight demo目录介绍<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h2>
<p>docker镜像内demo目录介绍</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
在产品发布包中提供了Knight镜像，进入镜像后在目录/TS-KnightDemo下存放的是Knight的示例，主目录结构如下图所示:

|C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\526908931.bmp|

+----------+------------------------+----------------------------------+
| **一     | **                     | **简介**                         |
| 级目录** | 二级目录**             |                                  |
+==========+========================+==================================+
| R        | Classification         | 图                               |
| esources |                        | 像分类场景demo的模型，数据和代码 |
|          |                        |                                  |
|          |                        | - data                           |
|          |                        |   目录存放量化数据和测试数据     |
|          |                        |                                  |
|          |                        | - resnet18 目录存放resnet18模型  |
|          |                        |                                  |
|          |                        | - pysrc目录下存放python相关代码  |
|          |                        |                                  |
|          |                        | - csrc目录下存放C语言相关代码    |
+----------+------------------------+----------------------------------+
|          | ObjectDetection        | 图                               |
|          |                        | 像检测场景demo的模型，数据和代码 |
|          |                        |                                  |
|          |                        | - data                           |
|          |                        |   目录存放量化数据和测试数据     |
|          |                        |                                  |
|          |                        | - yolov5 目录存放yolov5模型      |
|          |                        |                                  |
|          |                        | - pysrc目录下存放python相关代码  |
|          |                        |                                  |
|          |                        | - csrc目录下存放C语言相关代码    |
+----------+------------------------+----------------------------------+
|          | Asr                    | 语                               |
|          |                        | 音检测场景demo的模型，数据和代码 |
|          |                        |                                  |
|          |                        | - data                           |
|          |                        |   目录存放量化数据和测试数据     |
|          |                        |                                  |
|          |                        | - gru 目录存放gru模型            |
|          |                        |                                  |
|          |                        | - pysrc目录下存放python相关代码  |
|          |                        |                                  |
|          |                        | - csrc目录下存放C语言相关代码    |
+----------+------------------------+----------------------------------+
|          | RNESimLibForDemo       | Knight demo 依赖的RNE模拟库      |
+----------+------------------------+----------------------------------+
|          | FinetuneLib            | 量化QAT                          |
|          |                        | demo示例，参见章节               |
|          |                        | \ `Finetune &lt;#finetune库demo&gt;`__ |
+----------+------------------------+----------------------------------+
|          | KnightMC               | Knig                             |
|          |                        | htMC模型压缩demo示例，参见章节\  |
|          |                        | `Knight-MC &lt;#knight-mc库demo&gt;`__ |
+----------+------------------------+----------------------------------+
| Scripts  | yol                    | Scripts目录                      |
|          | ov5_pytorch_chipAll.sh | 下，每个shell脚本对应一个demo。  |
|          |                        |                                  |
|          | yolov5_onnx_chipAll.sh | 命名规则如下：                   |
|          |                        |                                  |
|          | … …                    | - mod                            |
|          |                        | elname_modelframework_chipAll.sh |
|          |                        |                                  |
|          |                        | - modelname表示模型名称；        |
|          |                        |                                  |
|          |                        | - mo                             |
|          |                        | delframework表示浮点模型的框架； |
|          |                        |                                  |
|          |                        | - chipAll表示该模型              |
|          |                        | 所有芯片均支持，假如仅正在某几款 |
|          |                        | 芯片上支持该demo，则名称后缀改为 |
|          |                        | chipCDEF，代表支持4款对应芯片。  |
|          |                        |                                  |
|          |                        | 比如                             |
|          |                        | yol                              |
|          |                        | ov5_pytorch_chipAll.sh对应demo1, |
|          |                        | 表示浮点模型yolov5，             |
|          |                        | 原始模型框架为pytorch，使用ONNX  |
|          |                        | 量                               |
|          |                        | 化工具量化，且在所有芯片都支持。 |
+----------+------------------------+----------------------------------+

docker镜像外demo目录介绍
</pre></div>
</div>
<p>RNE运行时库的示例在容器外交付目录，对应不同芯片分别为</p>
<p><em>/TX510x-Lib、/TX5336x-TX5256x-Lib、/TX5368x_TX5339X_TX5335X-Lib、/TX5215x_TX5239x200_TX5239x220_TX5239x300-Lib、/TX5112x_TX5239x201-Lib。</em></p>
<p>其中RNE-RT-Lib_xxxx.tar.gz为RNE运行时库使用。</p>
</section>
<section id="id3">
<h2>Knight demo运行方式<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h2>
<p>Knight快速上手指南提供两种运行方式：一种是通过Knight
demo命令行方式运行演示；二是可通过demo脚本运行。</p>
<p>通过demo命令行运行</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
在启动容器后，输入Knight --chip TX5368AV200 demo
-h，界面示例如下图所示：

|C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\418085544.bmp|

请注意，当--framework为不同量化框架时，可演示的模型范围有所不同。

+-------------+--------+--------+-------------------------------------+
| *           | *      | **默   | **说明**                            |
| *参数名称** | *必需/ | 认值** |                                     |
|             | 可选** |        |                                     |
+=============+========+========+=====================================+
| -f或        | 必需   | 无     | 表示                                |
| --framework |        |        | 原始模型框架类型，可选范围{pytorch, |
|             |        |        | tf, onnx, paddle, caffe}            |
+-------------+--------+--------+-------------------------------------+
| -m或-       | 必需   | 无     | 表示当前demo中的模型名称。          |
| -model-name |        |        |                                     |
+-------------+--------+--------+-------------------------------------+
| -s或--step  | 可选   | all    | 表示demo演示的阶段，该              |
|             |        |        | 参数可选，默认all，取值范围{quant,  |
|             |        |        | rne, rne-sim-lib,all}：             |
|             |        |        |                                     |
|             |        |        | - quant表示对demo模型进行量         |
|             |        |        | 化，同时会对原始浮点模型进行推理测  |
|             |        |        | 试、对量化后定点模型进行推理测试。  |
|             |        |        |                                     |
|             |        |        | - rne表示对量化后的dem              |
|             |        |        | o模型进行编译、模拟推理、性能分析。 |
|             |        |        |                                     |
|             |        |        | - rne-sim-lib表示对已经开发好的     |
|             |        |        | C代码app进行编译链接模拟库并运行。  |
|             |        |        |                                     |
|             |        |        | - all                               |
|             |        |        |   表示顺序运行                      |
|             |        |        | 上述quant\\rne\\rne-sim-lib全流程。 |
|             |        |        |                                     |
|             |        |        | 注意                                |
|             |        |        | ，需要先运行quant后，才可运行rne，  |
|             |        |        | rne运行后，才可运行rne-sim-lib。    |
+-------------+--------+--------+-------------------------------------+
| -h或--help  | 可选   | 无     | 显示帮助信息。                      |
+-------------+--------+--------+-------------------------------------+

通过demo脚本运行
~~~~~~~~~~~~~~~~

Knight
demo示例也可通过Knight中demo脚本运行，具体脚本可参见\ `章节3 &lt;#模型部署资源生成快速指南&gt;`__\ 中重要步骤说明。

开发流程
========

AI全栈应用开发流程
------------------

|\\\\192.168.60.89\\home$\\chenfan\\Desktop\\Knight全栈应用场景图V1.3.jpg|

Knight工具链支持端侧AI应用全栈开发，包括应用开发，模型部署资源生成和自定义算子开发三个主要流程。

应用开发：用户调用Knight RNE SDK
API编写自己的业务应用，C代码加载模型部署资源，链接模拟库在纯软件环境中仿真调试自己的应用，没问题后，链接板端库在板端进行部署。

模型部署资源生成：用户准备已训练好的浮点模型，使用Knight
量化工具量化成IR定点模型，然后对比量化精度，接着编译生成模型部署资源，进行模拟器结果验证以及Profiling性能调优。详见\ `章节3 &lt;#模型部署资源生成快速指南&gt;`__\ 。

自定义算子开发：当用户模型中存在芯片不支持的算子时，用户在量化后的IR模型中添加自定义算子层，之后进行IR模型编译生成模型部署资源；用户在应用开发时进行自定义算子的C代码实现，通过SDK
API相应接口进行自定义算子注册。最后，与整个应用程序一起进行模拟库上调测，板端库上部署。

浮点模型训练：用户在使用Knight工具链之前，需准备好已训练的浮点模型。

模型部署资源生成开发流程
------------------------

|image2|

1) 用户使用Knight量化工具将提前训练好的浮点模型量化成IR定点模型。

..

   Knight ONNX量化工具demo请参见\ `章节3.1 &lt;#量化过程&gt;`__\ 。

2) 用户使用Knight
   RNE编译器将IR定点模型编译成芯片部署资源(cfg和weight资源)。Knight
   RNE编译器demo示例请参见\ `章节3.2.3.1 &lt;#rne编译器&gt;`__\ 。

3) 用户使用Knight RNE模拟器对测试数据进行推理，也可以使用Knight
   RNE性能分析工具对模型进行性能分析。

..

   Knight RNE模拟器demo请参见\ `章节3.2.3.2 &lt;#rne模拟器&gt;`__\ 。

4) 同时用户也可以调用Knight
   RNE模拟库编写自己的业务应用在纯软件环境仿真自己的业务模型。Knight
   RNE模拟库demo请参见\ `章节4.1 &lt;#模拟库&gt;`__\ 。

5) 如果步骤3、4均通过，用户可以调用Knight
   RNE运行时库编写自己的实际业务应用，部署到清微芯片上。

..

   Knight
   RNE运行时库demo请参见\ `章节4.2 &lt;#运行时库&gt;`__\ ，板端部署示例请参见\ `章节4.3 &lt;#板端环境搭建及部署&gt;`__\ 。

6) 在步骤3中，如果模型推理性能不满足需求，则用户可使用Knight压缩工具（简称Knight-MC）将提前训练好的浮点模型进行压缩，得到体积更小，性能更优，更适合端侧部署的浮点模型。（可选）

..

   Knight-MC demo示例请参见\ `章节3.6 &lt;#knight-mc库demo&gt;`__\ 。

7) 在步骤1量化后，如果模型精度损失严重，用户可以使用QAT库，即Knight
   Finetune库编写自己的Finetune工具对浮点模型进行微调，得到更适合量化的浮点模型，之后再进行步骤1。（可选）

..

   Finetune 库demo示例请参见\ `章节3.5 &lt;#finetune库demo&gt;`__\ 。

   **注意：**

   在整个开发流程中有如下4个检查点：

   1.
   用户使用Knight量化工具完成量化操作后，需要使用精度比对工具查看量化后精度是否满足业务要求；

   2. 用户使用Knight
   RNE模拟器对测试数据进行推理后，需保证其推理结果和Knight量化工具推理结果一致；

   3. 用户使用Knight
   RNE模拟库对测试数据进行推理后，需保证其推理结果和Knight
   RNE模拟器推理结果一致；

   4. 用户使用Knight
   RNE运行时库对测试数据进行推理后，需保证其推理结果和Knight
   RNE模拟库推理结果一致；

   以上4个检查点若不满足预期，可联系清微技术人员进行支持。

   为便于用户快速进行检查点2，3的结果验证，提供model_check.py脚本，可参考《TS.Knight-使用指南综述》FAQ章节说明。

开发流程示例
------------

以图像分类业务和目标检测业务为例，说明Knight工具链在此类场景中的开发流程示例。

目标检测场景
~~~~~~~~~~~~

目标检测场景的开发流程如下图所示：

|image3|

(a) 浮点模型推理（用户已有业务流程）

- 用户对测试图片进行前处理，通过原始浮点模型得到浮点推理结果。

..

   然后进行后处理（比如NMS，非极大值抑制算法）等操作并绘制检测框，得到最终的目标检测结果。

(b) 浮点模型使用Knight工具链进行量化，编译，模拟推理

- 用户对量化图片进行前处理，使用Knight量化工具得到IR模型，接着通过Knight编译器得到cfg/weight资源。

- 用户准备测试图片进行同样的前处理操作，此时根据需要转化成量化模型所需的数据类型，保存为bin文件，和cfg/weight资源文件一并输入Knight
  RNE 模拟器得到定点推理结果。

- 用户需要将定点推理结果进行反量化和后处理绘制检测框得到目标检测结果。

(c) 板端推理

- 用户使用相同的测试图片，进行相同的图像前处理并转化为所需的dtype
  类型，然后使用RNE-RT-Lib将cfg/weight资源进行板端部署，得到定点推理结果。

- 用户需要将定点推理结果进行反量化和后处理绘制检测框得到和图(b)中相同的目标检测结果。

图像分类场景
~~~~~~~~~~~~

   图像分类场景的开发流程如下图所示：

|image4|

(a) 浮点模型推理（用户已有业务流程）

- 用户对测试图片进行前处理，通过原始浮点模型得到浮点推理结果。

..

   若模型最后一层是softmax，输出为不同类别的概率，此时使用argmax取最大值，则可得到图像分类结果；若模型最后一层是argmax,
   则可直接得到图像分类结果。

(b) 浮点模型使用Knight工具链进行量化，编译，模拟推理

- 用户对量化图片进行前处理，使用Knight量化工具得到IR模型，接着通过Knight编译器得到cfg/weight资源。

- 用户准备测试图片进行同样的前处理操作，此时根据需要转化成量化模型所需的dtype数据类型。比如：图片前处理中最后一步是减均值除方差操作，则前处理后数据类型为浮点。

..

   在使用量化工具时，若--ir-input-dtype指定为float32（默认），则此处的dtype为浮点类型，无需进行转换；若--ir-input-dtype指定为int8，则此处的dtype为int8，需要将浮点数据转换为int8类型。

- 接着将dtype类型数据保存为bin文件，和cfg/weight资源文件一并输入Knight
  RNE 模拟器得到定点推理结果，从而得到图像分类结果。

(c) 板端推理

- 用户使用相同的测试图片，进行相同的图像前处理并转化为所需的dtype
  类型，然后使用RNE-RT-Lib将cfg/weight资源进行板端部署，得到和图(b)中相同的定点推理结果。

模型部署资源生成快速指南
========================

在docker
容器下运行快速上手用例，需要进行docker环境准备，并运行容器，详细安装及使用步骤请参阅《TS.Knight-使用指南综述》。

Quant
-----

命令行运行方式
~~~~~~~~~~~~~~

Quant表示对demo模型进行浮点推理，量化以及量化后定点模型推理测试，命令如下所示：

# 以demo1为例演示onnx quant 流程

Knight --chip TX5368AV200 demo -f pytorch -m yolov5 --step quant

脚本运行方式
~~~~~~~~~~~~

demo1对应的shell脚本为/TS-KnightDemo/Scripts/yolov5_pytorch_chipAll.sh，以yolov5
pytorch浮点模型使用ONNX量化工具为例，运行方式如下：

#命令如下

bash /TS-KnightDemo/Scripts/yolov5_pytorch_chipAll.sh TX5368AV200 quant

重要步骤
~~~~~~~~

原始浮点模型推理过程
^^^^^^^^^^^^^^^^^^^^

在使用Knight量化工具之前，需要用户准备好训练充分的浮点模型。基于官方开源的yolov5项目进行图像检测，命令行如下所示：

cd /TS-KnightDemo/Resources/ObjectDetection/pysrc/yolov5_master

python detect.py --source
/TS-KnightDemo/Resources/ObjectDetection/data/test_data/bus.jpg
--weights yolov5s.pt --img 640

执行成功后会对source指向的图片进行目标检测，并在runs/detect/expN目录中输出以下两个文件：

注：（expN中的N为变数，会随着推理次数增加而递增）

bus.jpg：绘制了检测框的图片；

yolo_result.txt：保存了检测框信息的文件。

完整的浮点模型推理包含以下3个步骤：

1) **前处理**

前处理过程一般包括resize调整大小、reshape矩阵转换、减均值除方差标准化等预处理。量化数据、测试数据均遵循此方法。

2) **模型推理**

..

   预处理后的数据输入到原始浮点模型中，推理得到浮点输出结果。

3) **后处理**

..

   将浮点输出结果进行边界框回归和非极大值抑制等后处理操作，得到最终目标检测框的坐标，格式为

   [x, y, w, h, conf, label]，保存在文本.
   txt中，并在图像中绘制检查框得到bus.jpg。

量化过程
^^^^^^^^

**ONNX 量化**

   ONNX量化工具内集成了TF2ONNX, Caffe2ONNX, Pytorch2ONNX,
   Paddle2ONNX转换工具，不仅支持ONNX

浮点模型的量化还可支持Tensorflow, Caffe,
Pytorch和PaddlePadlle浮点模型的转换和量化。

   此处以yolov5 pytorch浮点模型使用ONNX量化工具为例进行说明。

- 数据预处理

Infer推理函数存放在目录/TS-KnightDemo/Resources/ObjectDetection/pysrc/TS_yolov5_onnx_from_ts中，调用/TS-KnightDemo/Resources/ObjectDetection/pysrc/TS_yolov5_onnx_from_ts/yolov5_onnx_ts.py中的预处理函数

|C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\1279412600.bmp|

|C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\2902189734.bmp|

ONNX 量化使用转换命令和量化分步完成：

- **模型转换**

..

   Knight --chip TX5368AV200 quant -m yolov5 -f pytorch -r convert -w
   /TS-KnightDemo/Resources/ObjectDetection/yolov5/yolov5s.pt -s
   /TS-KnightDemo/Output/yolov5_pytorch/quant -uds
   /TS-KnightDemo/Resources/ObjectDetection/pysrc/TS_yolov5_onnx_from_ts/yolov5_onnx_ts.py
   -l 3

- **模型量化**

量化转换后的yolov5模型：

   #命令

   Knight --chip TX5368AV200 quant --run-config
   /TS-KnightDemo/Scripts/yolov5_config.json -m
   /TS-KnightDemo/Output/yolov5_pytorch/quant/yolov5.onnx -f onnx -if
   infer_yolov5 --save-dir /TS-KnightDemo/Output/yolov5_pytorch/quant -d
   /TS-KnightDemo/Resources/ObjectDetection/data/quant_data/coco/images/val2017
   -uds
   /TS-KnightDemo/Resources/ObjectDetection/pysrc/TS_yolov5_onnx_from_ts/yolov5_onnx_ts.py
   -qid uint8 --dump

量化结果：

   量化后的模型保存在/TS-KnightDemo/Output/yolov5_pytorch/quant文件夹下，yolov5_quantize.onnx是量化后的模型文件。

   在yolov5的demo中，除了提供一个基础ONNX浮点模型做演示外，也额外提供了一个推理时间更短的ONNX模型做演示，这个模型是使用relu作为激活层的。

   具体实现可参考脚本/TS-KnightDemo/Scripts/yolov5_onnx_chipAll.sh，其中定义了一个变量use_relu_model，使用者可根据自身需要通过改变变量的取值来完成两个模型的使用切换。

此处以yolov5
ONNX的两个浮点模型使用ONNX量化工具生成子图为例，进行量化部分区别的说明。

- **子模型生成**

Onnx浮点模型在量化前，需要将模型里不支持的算子去掉重新保存为子模型，再进行下一步的量化。

使用模型yolov5s_v7.0.onnx生成子模型：

   #命令

   Knight --chip TX5368AV200 quant --run-config
   /TS-KnightDemo/Scripts/yolov5_config.json -m
   /TS-KnightDemo/Resources/ObjectDetection/yolov5/yolov5s_v7.0.onnx -f
   onnx -if infer_yolov5 --save-dir
   /TS-KnightDemo/Output/yolov5_onnx/quant -d
   /TS-KnightDemo/Resources/ObjectDetection/data/quant_data/coco/images/val2017
   -uds
   /TS-KnightDemo/Resources/ObjectDetection/pysrc/TS_yolov5_onnx_from_torch/yolov5_onnx.py
   -qid uint8 --dump --output-name /model.24/m.0/Conv_output_0
   /model.24/m.1/Conv_output_0 /model.24/m.2/Conv_output_0

使用relu激活的模型yolov5s_v7.0_relu.onnx生成子模型：

   #命令

   #使用relu激活的模型yolov5s_v7.0_relu.onnx

   Knight --chip TX5368AV200 quant --run-config
   /TS-KnightDemo/Scripts/yolov5_config.json -m
   /TS-KnightDemo/Resources/ObjectDetection/yolov5/yolov5s_v7.0_relu.onnx
   -f onnx -if infer_yolov5 --save-dir
   /TS-KnightDemo/Output/yolov5_onnx/quant -d
   /TS-KnightDemo/Resources/ObjectDetection/data/quant_data/coco/images/val2017
   -uds
   /TS-KnightDemo/Resources/ObjectDetection/pysrc/TS_yolov5_onnx_from_torch/yolov5_onnx.py
   -qid uint8 --dump --output-name 269 324 379

   **注意：**

   在量化命令中有2点注意事项：

   1. 指定--std,--mean
   ,将标准化操作融合到模型中，可加速应用在芯片上的推理性能，同时需指定量化后定点模型输入数据类型uint8,
   即-qid uint8;

   2.
   量化后定点模型推理得到定点结果，需要进行反量化操作，才可进行后处理。若指定-od,
   则量化时自动在定点模型中追加反量化层，定点模型推理后无需再进行反量化。

量化后定点模型推理过程
^^^^^^^^^^^^^^^^^^^^^^

**ONNX 量化**

- 定点推理

ONNX量化后定点模型推理命令如下所示:

Knight --chip TX5368AV200 quant --run-config
/TS-KnightDemo/Scripts/yolov5_config.json -r infer -d
/TS-KnightDemo/Resources/ObjectDetection/data/test_data/bus.jpg -m
/TS-KnightDemo/Output/yolov5_pytorch/quant/yolov5_quantize.onnx -f onnx
--save-dir /TS-KnightDemo/Output/yolov5_pytorch/quant -uds
/TS-KnightDemo/Resources/ObjectDetection/pysrc/TS_yolov5_onnx_from_ts/yolov5_onnx_ts.py

推理结果：

推理后的结果保存在/TS-KnightDemo/Output/yolov5_pytorch/quant文件夹下，

result_0_p.txt, result_1_p.txt, result_2_p.txt是推理后的结果文件。

- 后处理

量化后定点模型推理指令中，也在内部调用了后处理操作，结果保存为

yolov5_result.jpg

- **MAP示范**

在yolov5的量化过程中，我们使用了多张图片做为量化数据集，在模型量化后，也提供了批量推理图片并展示MAP指标的步骤。

ONNX定点模型批量推理命令如下所示：

Knight --chip TX5368AV200 quant -r infer -m
/TS-KnightDemo/Output/yolov5_pytorch/quant/yolov5_quantize.onnx -f onnx
-if infer_yolov5 -s /TS-KnightDemo/Output/yolov5_pytorch/quant -d
/TS-KnightDemo/Resources/ObjectDetection/data/quant_data/coco/images/val2017
-uds
/TS-KnightDemo/Resources/ObjectDetection/pysrc/TS_yolov5_onnx_from_ts/yolov5_onnx_ts.py

   MAP的参数如图所示：

   |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\1648505005.bmp|

**注意：在量化时指定-od，此处定点模型推理后无需再进行反量化。**

检查点
^^^^^^

此时可进行检查点1的检验，对比原始浮点模型的目标检测结果和ONNX量化后的目标检查结果。

Pytorch yolov5原始浮点模型推理后的结果为：

/TS-KnightDemo/Resources/ObjectDetection/pysrc/yolov5_master/runs/detect/expN/bus.jpg

经过ONNX量化后的结果为：

/TS-KnightDemo/Output/yolov5_pytorch/quant/yolov5_result.jpg

若不满足，可使用精度对比工具（参见\ `章节3.4 &lt;#compare&gt;`__\ ）进行问题定位。

RNE
---

.. _命令行运行方式-1:

命令行运行方式
~~~~~~~~~~~~~~

RNE表示对量化后的demo模型进行RNE编译器编译、RNE模拟器推理、RNE性能分析器评估性能。

RNE demo命令如下所示：

# 以demo1为例演示RNE流程

Knight --chip TX5368AV200 demo -f pytorch -m yolov5 --step rne

.. _脚本运行方式-1:

脚本运行方式
~~~~~~~~~~~~

以yolov5
pytorch浮点模型使用ONNX量化工具为例，在目录/TS-KnightDemo/Scripts/yolov5_pytorch_chipAll.sh中RNE阶段对应的脚本如下所示：

#命令

bash /TS-KnightDemo/Scripts/yolov5_pytorch_chipAll.sh TX5368AV200 rne

.. _重要步骤-1:

重要步骤
~~~~~~~~

RNE编译器
^^^^^^^^^

RNE编译命令如下所示：

Knight compile --chip TX5368AV200 --onnx
/TS-KnightDemo/Output/yolov5_pytorch/quant/yolov5_quantize.onnx
--save-dir /TS-KnightDemo/Output/yolov5_pytorch/rne

RNE模拟器
^^^^^^^^^

   在模拟器上跑编译后的模型仿真

1) **测试图像经过前处理得到.bin**

python3
/TS-KnightDemo/Resources/ObjectDetection/pysrc/TS_yolov5_onnx_from_ts/yolov5_onnx_ts.py
--input /TS-KnightDemo/Resources/ObjectDetection/data/test_data/bus.jpg
--outpath /TS-KnightDemo/Output/yolov5_pytorch/rne --pre_processing

   执行成功后会输出文件：

   model_input.bin文件，可作为模拟器的输入使用。

2) **使用模拟器推理一条测试数据**

Knight --chip TX5368AV200 run --input
/TS-KnightDemo/Output/yolov5_pytorch/rne/model_input.bin --model
/TS-KnightDemo/Output/yolov5_pytorch/rne/yolov5_quantize_r.tsmodel
--save-dir /TS-KnightDemo/Output/yolov5_pytorch/rne -fmt nchw

执行该命令后，得到以下三路输出文件：

   result-357_p.txt，result-358_p.txt，result-359_p.txt，维度分别为[1,
   255, 80, 80]，[1, 255, 40, 40]，[1, 255, 20,
   20]，这三个文件中保存了模拟器定点的输出数据。

3) **模拟器输出结果后处理**

#将模拟器输出的三个结果文件result-357_p.txt，result-358_p.txt，result-359_p.txt读入，做反量化及NMS等后处理后，获得预测框信息。

python3
/TS-KnightDemo/Resources/ObjectDetection/pysrc/TS_yolov5_onnx_from_ts/yolov5_onnx_ts.py
--input /TS-KnightDemo/Output/yolov5_pytorch/rne --outpath
/TS-KnightDemo/Output/yolov5_pytorch/rne --proc-mode pytorch_use_onnx
--post_processing --data
/TS-KnightDemo/Resources/ObjectDetection/data/test_data/bus.jpg

执行完毕后，会在outpath指向的目录中输出下内容：

   yolov5_result.jpg：检测结果图片。

result.txt：保存了检测框的文件。

RNE性能分析器
^^^^^^^^^^^^^

   RNE Profiling 执行命令如下：

Knight profiling --chip TX5368AV200 --model
/TS-KnightDemo/Output/yolov5_pytorch/rne/yolov5_quantize_r.tsmodel
--save-dir /TS-KnightDemo/Output/yolov5_pytorch/rne --log-level 3

.. _检查点-1:

检查点
^^^^^^

使用模拟器推理完成后，需要进行检查3与检查点2的数据result-357_p.txt，result-358_p.txt，result-359_p.txt对比，两者结果应完全一致，参见\ `章节3.3 &lt;#model_check&gt;`__\ 。

model_check
-----------

在执行完量化和编译的命令后可使用model_check.py进行检查点2和检查点3结果的验证，验证命令如下：

cd /TS-KnightSoftware/tools/model_check/

python model_check.py --quant-output
/TS-KnightDemo/Output/yolov5_pytorch/quant/dump --compile-output
/TS-KnightDemo/Output/yolov5_pytorch/rne --run-mode 0

|C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\1951423906.bmp|

compare
-------

在执行量化命令后，若发现结果存在不一致，可使用compare工具进行精度分析和比较，定位问题。

首先需要执行ONNX量化脚本, 并指定--dump模式

Knight --chip TX5368AV200 quant -m
/TS-KnightDemo/Output/yolov5_pytorch/quant/yolov5.onnx -f onnx -if
infer_yolov5 -s /TS-KnightDemo/Output/yolov5_pytorch/quant -bs 1 -qm
min_max -d
/TS-KnightDemo/Resources/ObjectDetection/data/quant_data/coco128/images/train2017
-uds
/TS-KnightDemo/Resources/ObjectDetection/pysrc/TS_yolov5_onnx_from_ts/yolov5_onnx_ts.py
--mean 0.0 0.0 0.0 --std 255.0 255.0 255.0 -qid uint8 --dump

|C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\2460229605.bmp|

然后可执行精度比对工具

#命令

Knight --chip TX5368AV200 compare -qd
/TS-KnightDemo/Output/yolov5_pytorch/quant

|C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\2600655677.bmp|

Finetune库demo
--------------

demo文件夹说明
~~~~~~~~~~~~~~

用例在容器内的路径:
*/TS-KnightDemo/Resources/FinetuneLib/cifar10_example*,目录结构如下：

+----------------+-----------------------------------------------------+
| **             | **说明**                                            |
| 文件夹或文件** |                                                     |
+================+=====================================================+
| checkpoint     | 训练完成后生成该文件夹并存放训练的浮点模型Res       |
|                | Net18_ckpt.pth、Finetune后的模型ResNet18_ckpt_q.pth |
+----------------+-----------------------------------------------------+
| data           | 存放Finetune所需的训练数据及测试数据                |
+----------------+-----------------------------------------------------+
| models         | 存放模型文件                                        |
+----------------+-----------------------------------------------------+
| script         | 存放运行此用例的脚本,                               |
|                |                                                     |
|                | 其中train.sh为浮点模型训练脚本,                     |
|                | finetune.sh为浮点模型Finetune训练脚本,              |
|                |                                                     |
|                | test.sh为对浮点模型及Finetune模型进行测试的脚本,    |
|                |                                                     |
|                | run_e2e_example.sh为总执行入口脚本                  |
+----------------+-----------------------------------------------------+
| main.py        | Finetune主函数入口文件                              |
+----------------+-----------------------------------------------------+
| utils.py       | Finetune运行时所依赖的函数文件                      |
+----------------+-----------------------------------------------------+

demo运行说明
~~~~~~~~~~~~

执行如下命令：

cd /TS-KnightDemo/Resources/FinetuneLib/cifar10_example/script

sh run_e2e_example.sh

执行成功后，会看到以下信息：

步骤一：train.sh结果如下图：

|image5|

步骤二：finetune.sh结果如下图：

|image6|

步骤三：test.sh结果如下图：

|image7|

最终结果保存在/TS-KnightDemo/Resources/FinetuneLib/cifar10_example/checkpoint目录下

+--------------------+-------------------------------------------------+
| **文件夹或文件**   | **说明**                                        |
+====================+=================================================+
| ResNet18_ckpt.pth  | 浮点模型文件。                                  |
+--------------------+-------------------------------------------------+
| R                  | Finetune后模型文件。                            |
| esNet18_ckpt_q.pth |                                                 |
+--------------------+-------------------------------------------------+

注意：

因为演示需要，浮点模型只训练了一个epoch，要想获得更好的浮点精度和Finetune精度可以在train.py里增加epoch数量。

重要步骤说明
~~~~~~~~~~~~

在Knight镜像内/TS-KnightDemo/Resources/FinetuneLib/cifar10_example/main.py是Finetune-Lib运行的必须脚本，执行python
main.py -h 可以获得如下图所示的命令行参数：

|image8|

1) **训练浮点模型**

python main.py ResNet18 --epochs 1

执行train.sh，其中ResNet18为模型名称，epochs为epoch的数量，执行完成后会生成ResNet18_ckpt.pth

2) **Finetune浮点模型**

python main.py ResNet18 --resume --BackendType TSQAT --quantize --lr
1e-5 --epochs 1

执行finetune.sh，其中ResNet18为模型名称，BackendType
为后端的名称，epochs为epoch的数量，lr为学习率，--quantize使能Finetune功能，执行完成后会生成ResNet18_ckpt_q.pth

3) **测试原始浮点模型和Finetune浮点模型的精度**

python main.py ResNet18 --resume -e

python main.py ResNet18 --resume --quantize -e

执行test.sh，其中ResNet18为模型名称，resume为指定训练好的模型，--quantize使能Finetune功能，-e为仅仅进行模型测试而不做训练。

4) **编译量化后的模型**

..

   参见\ `章节3.2.3.1 &lt;#rne编译器&gt;`__

5) **在RNE模拟器上跑编译后的模型**

..

   参见\ `章节3.2.3.2 &lt;#rne模拟器&gt;`__

Knight-MC库demo
---------------

Knight-MC库结合cifar10开源数据集提供一个图像分类业务的用例，网络结构是resnet18，模型输入为cifar10原始数据，输出结果为10分类的结果。

.. _demo文件夹说明-1:

demo文件夹说明
~~~~~~~~~~~~~~

用例在容器内的路径: */TS-KnightDemo/Resources/KnightMC/*,目录结构如下：

+-----------------------+----------------------------------------------+
| **文件夹或文件**      | **说明**                                     |
+=======================+==============================================+
| dataset               | 存放所需的训练数据和测试数据                 |
+-----------------------+----------------------------------------------+
| pretrained_model      | 存放预训练的图像分类模型                     |
+-----------------------+----------------------------------------------+
| resnet18_cifar        | Resnet18图像分类模型压缩示例                 |
|                       |                                              |
|                       | pruning\_                                    |
|                       | config.yaml：Pruning工具配置文件示例         |
|                       |                                              |
|                       | sparsity                                     |
|                       | config.yaml：Sparsity工具配置文件示例        |
|                       |                                              |
|                       | pruning_demo.py：调用Pruning工具代码示例     |
|                       |                                              |
|                       | sparsity_demo.py：调用Sparsity工具代码示例   |
|                       |                                              |
|                       | resnet_cifar.py: resnet模型结构定义          |
|                       |                                              |
|                       | train_val.py:                                |
|                       | 训练模型代码，包含数据加载处理代码           |
+-----------------------+----------------------------------------------+

.. _demo运行说明-1:

demo运行说明
~~~~~~~~~~~~

Pruning Demo剪枝脚本执行如下命令：

# 工作路径 */TS-KnightDemo/Resources/KnightMC/resnet18_cifar*

python pruning_demo.py

Sparsity Demo稀疏脚本执行如下命令：

# 工作路径 */TS-KnightDemo/Resources/KnightMC/resnet18_cifar*

python sparsity_demo.py

注意：

因为演示需要，Pruning剪枝训练次数设置次数较小warmup: 10，
num_heatup_episodes：10。

同时，稀疏或剪枝后模型重训练只训练了2个epoch，要想获得更好的浮点精度可以在pruning_demo.py或sparsity_demo.py里增加epoch数量。

.. _重要步骤说明-1:

重要步骤说明
~~~~~~~~~~~~

Pruning Demo重要步骤说明
^^^^^^^^^^^^^^^^^^^^^^^^

1) **准备预训练的浮点模型**

在示例中，已准备好预训练的浮点模型，在目录/TS-KnightDemo/Resources/KnightMC/pretrained_model中。

   同时用户自行训练得到浮点模型，训练脚本如下：

   python train_val.py

2) **配置yaml文件**

..

   若不结合Knight工具链，仅考虑模型精度，不考虑模型在芯片上的推理时间，则需要将配置文件pruning_config.yaml中参数run_knight设置为False。

3) **剪枝浮点模型和重训练浮点模型**

执行如下脚本同时完成剪枝和重训练过程，若无需进行重训练则将代码中重训练部分进行屏蔽即可。

   python pruning_demo.py

执行该脚本，剪枝后的模型保存在/TS-KnightDemo/Resources/KnightMC/resnet18_cifar/output目录下:

|image9|

其中kmc-pruning.csv文件内容如下所示：

|image10|

   重训练之后的模型保存在/ TS-KnightDemo
   /Resources/KnightMC/resnet18_cifar/logs目录下

|image11|

   pruning_demo.py中包含了测试重训练模型精度的步骤，页面输入示例如下：

|image12|

4) **编译量化后的模型**

..

   参见\ `章节3.2.3.1 &lt;#rne编译器&gt;`__

5) **在RNE模拟器上跑编译后的模型**

..

   参见\ `章节3.2.3.2 &lt;#rne模拟器&gt;`__

Sparsity Demo重要步骤说明
^^^^^^^^^^^^^^^^^^^^^^^^^

1) **准备预训练的浮点模型**

在示例中，已准备好预训练的浮点模型，在目录/TS-KnightDemo/Resources/KnightMC/pretrained_model中。

同时用户自行训练得到浮点模型，训练脚本如下：

   python train_val.py

2) **配置yaml文件**

在配置文件sparsity_config.yaml中配置参数sparsity_method选择不同的稀疏方式。

3) **稀疏浮点模型和重训练浮点模型**

执行如下脚本同时完成稀疏和重训练过程，若无需进行重训练则将代码中重训练部分进行屏蔽，同时增加保存稀疏后模型的代码即可。

   python sparsity_demo.py

执行该脚本，稀疏并重训练后模型后的模型保存在

*/TS-KnightDemo/Resources/KnightMC/resnet18_cifar/logs*\ 目录下：

   |image13|

sparsity_demo.py中包含了测试重训练模型精度的步骤，页面输入示例如下：

   |image14|

4) **编译量化后的模型**

..

   参见\ `章节3.2.3.1 &lt;#rne编译器&gt;`__

5) **在RNE模拟器上跑编译后的模型**

..

   参见\ `章节3.2.3.2 &lt;#rne模拟器&gt;`__

应用开发快速指南
================

模拟库
------

.. _命令行运行方式-2:

命令行运行方式
~~~~~~~~~~~~~~

模拟库demo表示对已经开发好的C代码app进行编译链接模拟库并运行，demo命令示例如下所示：

# 以demo1为例演示rne-sim-lib流程

Knight --chip TX5368AV200 demo -f pytorch -m yolov5 --step rne-sim-lib

.. _脚本运行方式-2:

脚本运行方式
~~~~~~~~~~~~

以yolov5
pytorch浮点模型使用ONNX量化工具为例，在目录/*TS-KnightDemo/Scripts/
yolov5_pytorch_chipAll.sh*\ 中rne-sim-lib阶段对应的脚本如下所示：

#命令

bash /TS-KnightDemo/Scripts/yolov5_pytorch_chipAll.sh TX5368AV200
rne-sim-lib

.. _重要步骤-2:

重要步骤
~~~~~~~~

1) C代码开发

编写/TS-KnightDemo/Resources/ObjectDetection/csrc/yolov5_simlib/src/main.cpp.

主要API接口说明

为了方便用户使用，模拟库和运行时库提供了一套C形式的API接口。主要API接口说明如下：

C接口说明（部分）：

+---------------+-----------+-------------+---------------------------+
| **接口名称**  | **功      | **参数名    | **返回值**                |
|               | 能描述**  | 称及描述**  |                           |
+===============+===========+=============+===========================+
| TS_MPI_TRP_   | 初        | ne          | 0表示成功，非0表示失败    |
| RNE_LoadModel | 始化单个  | t：网络指针 |                           |
|               | NN网络。  |             |                           |
+---------------+-----------+-------------+---------------------------+
| TS_MPI_TR     | 网络      | ne          | 若返回为N                 |
| P_RNE_Forward | 前向推理  | t：网络指针 | ULL，则前向推理出现异常； |
|               |           |             |                           |
|               |           |             | 若网络                    |
|               |           |             | 的cpDebugLayerName不为空  |
|               |           |             |                           |
|               |           |             | 且能找到该调试层          |
|               |           |             | ，则返回该调试层的输出；  |
|               |           |             |                           |
|               |           |             | 否则返回网络的最后结果    |
|               |           |             | ，等同于函数TS_MPI_TRP_R  |
|               |           |             | NE_GetResultBlobs的返回值 |
+---------------+-----------+-------------+---------------------------+
| TS_MPI_TRP_RN | 释放单    | ne          | 0表示成功，非0表示失败    |
| E_UnloadModel | 个网络。  | t：网络指针 |                           |
+---------------+-----------+-------------+---------------------------+
| TS_MPI_       | 注册通用  | ne          | 0表示成功，非0表示失败    |
| TRP_RNE_Regis | 算子层自  | t：网络指针 |                           |
| terGpUserData | 定义数据  |             |                           |
|               |           | la          |                           |
|               |           | yerId：层id |                           |
|               |           |             |                           |
|               |           | use         |                           |
|               |           | rData：自定 |                           |
|               |           | 义数据指针  |                           |
+---------------+-----------+-------------+---------------------------+

2) 执行make命令进行编译、运行

在simlib目录下执行make指令进行编译，会在build_sim/Release/RNE_Sim_Lib_demo.elf
目录下生成一个仿真elf文件，该文件可以直接在终端执行。

   #
   工作目录：/TS-KnightDemo/Resources/ObjectDetection/csrc/yolov5_simlib

   make EXPORT_DIR=../../../RNESimLibForDemo/RNESimLibD

|C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\299473666.bmp|

   #
   工作目录：/TS-KnightDemo/Resources/ObjectDetection/csrc/yolov5_simlib

   # 运行命令

   ./build_sim/Release/RNE_Sim_Lib_demo.elf
   /TS-KnightDemo/Output/yolov5_pytorch/rne/yolov5_quantize_r.cfg
   /TS-KnightDemo/Output/yolov5_pytorch/rne/yolov5_quantize_r.weight
   /TS-KnightDemo/Resources/ObjectDetection/data/test_data/bus.jpg
   /TS-KnightDemo/Output/yolov5_pytorch

|C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\1305397667.bmp|

模拟库输出的图片yolov5_simlib_result.jpg与TS-RNE-Simulator
输出的bus_sim.jpg对比，结果一致。

.. _检查点-2:

检查点
^^^^^^

使用模拟器推理完成后，需要进行检查点4与检查点3的数据或者图片的对比，两者结果应一致。

运行时库
--------

相关文件说明
~~~~~~~~~~~~

容器外/TX5368x_TX5339x_TX5335x_Lib/RNE-RT-Lib/samples目录下有关文件如下：

+-----------------+----------------------------------------------------+
| *               | **说明**                                           |
| *文件夹或文件** |                                                    |
+=================+====================================================+
| compiled_model  | 如                                                 |
|                 | 果无指定路径，脚本默认此文件夹为模拟器输入文件夹。 |
|                 |                                                    |
|                 | DNN_S_mfcc：根据网络名称创建的文件夹。             |
|                 |                                                    |
|                 | model_r.cfg：网络指令文件。                        |
|                 |                                                    |
|                 | model_r.weight：网络权重文件。                     |
|                 |                                                    |
|                 | model_input.bin：网络输入文件。                    |
|                 |                                                    |
|                 | 其他网络。                                         |
+-----------------+----------------------------------------------------+
| rne             | 演示一般网络基本推理过程的示例程序。               |
| _simple_forward |                                                    |
+-----------------+----------------------------------------------------+
| rne_set_i       | 此demo演示用户通过物理地址的方式加载输入数据。     |
| nput_blobs_addr |                                                    |
+-----------------+----------------------------------------------------+
| rne_y           | 此demo演示yolov5的前处理、推理、后处理的完整流程。 |
| olov5_detection |                                                    |
+-----------------+----------------------------------------------------+
| Scripts         | 用例运行脚本及依赖的工具。                         |
|                 |                                                    |
|                 | bin2header：二进制文件转头文件脚本。               |
|                 |                                                    |
|                 | run_e2e_example.sh: 总执行入口脚本。               |
|                 |                                                    |
|                 | run_e2e_example_cm.sh: 指定demo和模型路径编译。    |
+-----------------+----------------------------------------------------+

.. _demo运行说明-2:

demo运行说明
~~~~~~~~~~~~

以rne_yolov5_detection为例，执行如下命令：

#工作路径：examples/rne_yolov5_detection

执行命令：make clean ; make;

   执行成功后，会看到以下信息提示，表示交叉编译成功，生成板端部署资源：
   *examples/*\ rne_yolov5_detection
   */build_linux_a53/Release/*\ rne_yolov5_detection\ *.elf。*

|image15|

资源成功生成后,如何在板端部署运行，请参见\ `章节4.3 &lt;#板端环境搭建及部署&gt;`__\ 。

板端环境搭建及部署
------------------

环境准备
~~~~~~~~

开发板环境的配置及与板端的初始化请参考《TX5368A Linux
SDK安装及升级使用说明_v1.5.pdf》第2章安装、升级TX5368A DEMO板开发环境。

板端运行
~~~~~~~~

配置交叉编译环境
^^^^^^^^^^^^^^^^

在RNE-RT-Lib目录下，有settings_path_linux.sh脚本。编辑该脚本将tools_dir设置成gcc-arm-10.2-2020.11-x86_64-arm-none-linux-gnueabihf.tar.xz
解压后的存放路径（最好是绝对路径），之后source一下就可以。

   # 工作目录：./RNE_RT_Lib

   # 命令

   vi settings_path_linux.sh

   # 编辑’tools_dir=xxxxxx’

   ...

   # 保存退出

   :wq

   #source 是使该文件生效

   source settings_path_linux.sh

|image16|

|image17|

打开串口调试工具
^^^^^^^^^^^^^^^^

确保连线正确，然后打开串口调试工具，可以使用SSCOM、SecureCRT或者其他的软件，本示例使用的是ipop,
确保IPOP工具TFTP已配置好服务器路径，确保打开对应的调试串口，确保板端已经进入linux系统。

拷贝部署资源到板端部署
^^^^^^^^^^^^^^^^^^^^^^

   把rne_yolov5_detection.elf以及examples/rne_yolov5_detection目录下resource文件夹拷贝到window系统下IPOP工具配置TFTP服务器目录下，

然后执行如下命令：

**通过tftp把文件拷贝到板端：**

   # 命令

   tftp –g –r rne_yolov5_detection.elf 192.168.1.20

**注：**\ 板端的连接配置请参考《TX5368A Linux SDK安装及升级使用说明》。

   **部署模型：**

   参数说明：

   参数1: resource/yolov5_quantize_r.cfg

   参数2: resource/yolov5_quantize_r.weight

   参数3: resource/1.jpg or resource/2.jpg or resource/3.jpg or
   resource/4.jpg

   参数4: 检测结果图片保存文件名(必须图片格式结尾)

   参数5: 前处理是否使用int8 hwc的格式, 0 : 不使用, 1 : 使用

   ./rne_yolov5_detection.elf 参数1 参数2 参数3 参数4 参数5

   注: 读入模型文件cfg和weight时, 需保证\*.cfg和\*.weight的前缀一致

   # 命令

   chmod +x rne_yolov5_detection.elf

   ./rne_yolov5_detection.elf resource/yolov5_quantize_r.cfg
   resource/yolov5_quantize_r.weight resource/4.jpg resource/bus.jpg

执行前的图片为4.jpg

|C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\3044964167.bmp|

然后可以看到模型运行结果如下图

|cat|

生成的识别后的图片如下：

|C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\1022032865.bmp|

   至此，模型部署完毕！

自定义算子开发快速指南
======================

.. _脚本运行方式-3:

脚本运行方式
------------

在目录/TS-KnightDemo/Scripts中对应的脚本运行如下所示：

#命令如下

bash /TS-KnightDemo/Scripts/resnet18_ops_caffe_caffe_chipD.sh
TX5368AV200 all

.. _重要步骤-3:

重要步骤
--------

1) 修改量化后的模型

..

   将预处理的resize和crop操作作为自定义算子层放在模型中，因此需要在量化后的prototxt模型中增加自定义算子层custom_resize和custom_crop,
   并修改连接层的bottom值。

   layer {

   name: &quot;custom_resize&quot;

   type: &quot;custom_resize&quot;

   bottom: &quot;data&quot;

   top: &quot;custom_resize&quot;

   ts_rce_layer{

   layer_type: 1153

   top_channel: 3

   top_width: 256

   top_height: 256

   }

   fix_param {

   input_bit: &quot;us8&quot;

   output_bit: &quot;us8&quot;

   }

   }

   layer {

   name: &quot;custom_crop&quot;

   type: &quot;custom_crop&quot;

   bottom: &quot;custom_resize&quot;

   top: &quot;custom_crop&quot;

   ts_rce_layer{

   layer_type: 1154

   top_channel: 3

   top_width: 224

   top_height: 224

   }

   fix_param {

   input_bit: &quot;us8&quot;

   output_bit: &quot;us8&quot;

   }

   }

2) 模型编译

#命令

Knight --chip TX5368AV200 compile --net
/TS-KnightDemo/Resources/Classification/resnet18/customized_model/resnet18_quant.prototxt
--weight
/TS-KnightDemo/Resources/Classification/resnet18/customized_model/resnet18_quant.caffemodel
–save-dir /TS-KnightDemo/Output/resnet18_customized/rne -gp 1

3) 自定义算子C语言实现

..

   首先注册自定义算子层：

   头文件ts_rne_gp_layers.h中新增如下代码，注意此处和ID
   和prototxt中层类型layer_type一致。

   |image18|

   文件ts_rne_gp_layers.c中新增如下代码：

   |image19|

   |image20|

   然后C语言实现自定义算子，即编写ts_rne_gp_custom_crop.c和ts_rne_gp_custom_resize.c。

4) 模拟库模拟

..

   切换至自定义算子的源码目录，并将编译后模型使用头文件生成工具做转换

#命令

cd /TS-KnightDemo/Resources/Classification/csrc/resnet18_customized

./bin2header
/TS-KnightDemo/Output/resnet18_ops_caffe/rne/resnet18_quant_r.cfg
./resnet18_cfg.h

./bin2header
/TS-KnightDemo/Output/resnet18_ops_caffe/rne/resnet18_quant_r.weight
./resnet18_weight.h

在/TS-KnightDemo/Resources/Classification/csrc/resnet18_customized目录下运行make命令，生成elf文件后运行

#命令

make clean

make

build_sim/Release/RNE_Sim_Lib_demo.elf
/TS-KnightDemo/Output/resnet18_ops_caffe/simlib/

5) 运行时库上板执行

参见运行时库的上板说明\ `章节4.2 &lt;#运行时库&gt;`__

.. |image1| image:: media/image5.png
   :width: 8.29931in
   :height: 0.17292in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\3720703816.bmp| image:: media/image6.png
   :width: 6.85833in
   :height: 2.80339in
.. |\\\\192.168.60.89\\home$\\chenfan\\Desktop\\流程图 (13).jpg| image:: media/image8.jpeg
   :width: 5.64306in
   :height: 3.25486in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\526908931.bmp| image:: media/image9.png
   :width: 6.85833in
   :height: 5.175in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\418085544.bmp| image:: media/image10.png
   :width: 6.85833in
   :height: 2.35694in
.. |\\\\192.168.60.89\\home$\\chenfan\\Desktop\\Knight全栈应用场景图V1.3.jpg| image:: media/image11.png
   :width: 6.15625in
   :height: 3.56458in
.. |image2| image:: media/image12.png
   :width: 3.73432in
   :height: 6.8314in
.. |image3| image:: media/image13.png
   :width: 5.98004in
   :height: 5.06148in
.. |image4| image:: media/image14.png
   :width: 6.85833in
   :height: 3.82292in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\1279412600.bmp| image:: media/image15.png
   :width: 6.85833in
   :height: 3.47431in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\2902189734.bmp| image:: media/image16.png
   :width: 5.22917in
   :height: 1.27569in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\1648505005.bmp| image:: media/image17.png
   :width: 6.85833in
   :height: 1.40208in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\1951423906.bmp| image:: media/image18.png
   :width: 6.85833in
   :height: 3.22222in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\2460229605.bmp| image:: media/image19.png
   :width: 6.23472in
   :height: 4.15in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\2600655677.bmp| image:: media/image20.png
   :width: 6.85833in
   :height: 2.82708in
.. |image5| image:: media/image21.png
   :width: 5.76806in
   :height: 1.04923in
.. |image6| image:: media/image22.png
   :width: 5.76806in
   :height: 2.04953in
.. |image7| image:: media/image23.png
   :width: 5.76806in
   :height: 1.66299in
.. |image8| image:: media/image24.png
   :width: 5.38497in
   :height: 2.16084in
.. |image9| image:: media/image25.png
   :width: 6.85833in
   :height: 0.33194in
.. |image10| image:: media/image26.png
   :width: 6.85833in
   :height: 0.80208in
.. |image11| image:: media/image27.png
   :width: 6.85833in
   :height: 0.35417in
.. |image12| image:: media/image28.png
   :width: 6.01042in
   :height: 0.53125in
.. |image13| image:: media/image29.png
   :width: 6.85833in
   :height: 0.35208in
.. |image14| image:: media/image30.png
   :width: 3.78125in
   :height: 0.57292in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\299473666.bmp| image:: media/image31.png
   :width: 6.59375in
   :height: 2.29861in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\1305397667.bmp| image:: media/image32.png
   :width: 6.85833in
   :height: 0.95278in
.. |image15| image:: media/image33.png
   :width: 6.85764in
   :height: 3.00625in
.. |image16| image:: media/image34.png
   :width: 2.66667in
   :height: 1.61806in
.. |image17| image:: media/image35.png
   :width: 4.24981in
   :height: 1.38817in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\3044964167.bmp| image:: media/image36.png
   :width: 4.38542in
   :height: 5.875in
.. |cat| image:: media/image37.png
   :width: 5.04167in
   :height: 2.38819in
.. |C:\\Users\\wangyanlong\\AppData\\Roaming\\feiq\\RichOle\\1022032865.bmp| image:: media/image38.png
   :width: 4.42708in
   :height: 5.91667in
.. |image18| image:: media/image39.png
   :width: 3.7186in
   :height: 0.28016in
.. |image19| image:: media/image40.png
   :width: 6.63575in
   :height: 0.26458in
.. |image20| image:: media/image41.png
   :width: 6.53522in
   :height: 0.33194in
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright COPYRIGHT© 2024北京清微智能科技有限公司, 保留所有权利。.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>